{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Creating a Well Designed Prompt\n",
    "\n",
    "In this lab you are going to build a well defined prompt to help describe a city (the one you currently live in, your hometown, or just a city you are interested in).\n",
    "\n",
    "We will start with a vague prompt just to get started, then build upon it.\n",
    "\n",
    "The goal is to have a good description of your city that you wouldn't mind sharing afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the usual libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from icecream import ic\n",
    "from common import simple_chat, show_response_detail\n",
    "\n",
    "# load our environment file\n",
    "load_dotenv()\n",
    "\n",
    "# define our API Key\n",
    "openai.api_key = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a vague prompt for information about the city you live in.  Or, if you prefer, your home town or another area you are attached to.\n",
    "\n",
    "Experiment with any of the parameters or instructions and see the impact to the completion.\n",
    "\n",
    "Think about the impact of the:\n",
    "* temperature\n",
    "* model\n",
    "* max_tokens\n",
    "* assistant instructions\n",
    "\n",
    "For example:\n",
    "\n",
    "long_message = \"Tell me about {location}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chat_args = {\n",
    "    'temperature': 0.5,\n",
    "    'model': 'gpt-3.5-turbo',\n",
    "    'max_tokens': 1000,\n",
    "}\n",
    "\n",
    "# don't forget to fill in the location and assistant instructions\n",
    "location = \"\"\n",
    "assistant_instructions = \"\"\n",
    "long_message = f\"\"\"\n",
    "Tell me about {location}.\n",
    "\"\"\"\n",
    "\n",
    "# build our messages to send to openAI.  These should be well formed JSON with a ROLE and CONTENT\n",
    "system_message = {\"role\":\"system\", \"content\": assistant_instructions}\n",
    "user_message = {\"role\":\"user\", \"content\": long_message}\n",
    "\n",
    "# we put these together into a single python list for processing together.\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "summary_response = simple_chat(messages=messages, **simple_chat_args)\n",
    "\n",
    "show_response_detail(summary_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine your prompt to include all the components of a well designed prompt: instruction, input data, and output format.\n",
    "\n",
    "For example:\n",
    "```\n",
    "long_message == \"\"\"\n",
    "Tell me about {location} in X paragraphs. Talk about XXXXXXX, YYYYYYY, and ZZZZZ.\n",
    "\n",
    "Give this writeup a title and output the text as QQQQQQQQ .\n",
    "\"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chat_args = {\n",
    "    'temperature': 0.5,\n",
    "    'model': 'gpt-3.5-turbo',\n",
    "    'max_tokens': 3000,\n",
    "}\n",
    "\n",
    "# don't forget to fill in the location and assistant instructions.\n",
    "location = \"\"\n",
    "assistant_instructions = \"\"\n",
    "\n",
    "long_message = f\"\"\"\n",
    "Tell me about {location}.\n",
    "\"\"\"\n",
    "\n",
    "# build our messages to send to openAI.  These should be well formed JSON with a ROLE and CONTENT\n",
    "system_message = {\"role\":\"system\", \"content\": assistant_instructions}\n",
    "user_message = {\"role\":\"user\", \"content\":long_message}\n",
    "\n",
    "# we put these together into a single python list for processing together.\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "summary_response = simple_chat(messages=messages, **simple_chat_args)\n",
    "\n",
    "show_response_detail(summary_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it all together - Instruction, Input Data, Context, and Formatting.\n",
    "- Break your instructions into smaller pieces.\n",
    "- Take a few shots at how you would like things to work.\n",
    "- Give formatting instructions.\n",
    "- Add leading text.\n",
    "\n",
    "For example:\n",
    "```\n",
    "long_message == \"\"\"\n",
    "Tell me about {location} in X paragraphs.\n",
    "####\n",
    "- Talk about XXXXXXX\n",
    "- Describe YYYYYYY\n",
    "- Discuss ZZZZZZZ\n",
    "- Mention  AAAAAAA\n",
    "\n",
    "- Explain the role of BBBBBB in city life.\n",
    "- Talk about the annual CCCCC \n",
    "\n",
    "Shot 1: Description\n",
    "Shot 2: Description\n",
    "Shot 3: Description\n",
    "\n",
    "Give this writeup a title and output the text as QQQQQQQQ .\n",
    "\n",
    "{location} - also known {nickname}\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "Experiment a few times with different models, temperatures, and max_tokens.  Also, try adjusting the system instructions.\n",
    "\n",
    "Take a look at the parameters again and see if you want to adjust them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chat_args = {\n",
    "    'temperature': 0.5,\n",
    "    'model': 'gpt-3.5-turbo',\n",
    "    # 'model': 'gpt-4',\n",
    "    'max_tokens': 3000,\n",
    "}\n",
    "# don't forget to fill in the location and assistant instructions.\n",
    "location = \"\"\n",
    "assistant_instructions = \"\"\n",
    "\n",
    "long_message = f\"\"\"\n",
    "Tell me about {location}.\n",
    "\"\"\"\n",
    "\n",
    "# build our messages to send to openAI.  These should be well formed JSON with a ROLE and CONTENT\n",
    "system_message = {\"role\":\"system\", \"content\": assistant_instructions}\n",
    "user_message = {\"role\":\"user\", \"content\":long_message}\n",
    "\n",
    "# we put these together into a single python list for processing together.\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "summary_response = simple_chat(messages=messages, **simple_chat_args)\n",
    "\n",
    "show_response_detail(summary_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment a few times with different models, temperatures, and max_tokens.  Also, try adjusting the system instructions.\n",
    "\n",
    "_*If you have some extra time*_ - write a loop to repeat the process for different locations and output the results to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
