{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Start a vague prompt for information about the city you live in now (or if you prefer, your home town or another town you are attached to.)\n",
    "2. Refine your prompt to include instruction, input data, and context.\n",
    "3. Add \"shots\" for things that you would like the output to focus on.\n",
    "4. Break your instructions down into smaller tasks.\n",
    "5. Give format instructions. If you aren't sure what to do here, just limit the number of sentences or paragraphs.\n",
    "6. Give leading text\n",
    "\n",
    "Experiment with a few features:\n",
    "1. The model.\n",
    "2. The temperature.\n",
    "3. Add an instruction to write for a specific audience (like a second grader.)\n",
    "4. Modify the leading text\n",
    "\n",
    "Try the same process for a different city or location.\n",
    "* What changed and what didn't?  What changed is the context, what didn't is the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Creating a Well Designed Prompt\n",
    "\n",
    "In this lab you are going to build a well defined prompt to help describe a city (the one you currently live in, your hometown, or just a city you are interested in).\n",
    "\n",
    "We will start with a vague prompt just to get started, then build upon it.\n",
    "\n",
    "The goal is to have a good description of your city that you wouldn't mind sharing afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the usual libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from icecream import ic\n",
    "from common import simple_chat, show_response_detail\n",
    "\n",
    "# load our environment file\n",
    "load_dotenv()\n",
    "\n",
    "# define our API Key\n",
    "openai.api_key = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a vague prompt for information about the city you live in.  Or, if you prefer, your home town or another area you are attached to.\n",
    "\n",
    "You can experiment with any of the parameters or instructions to get it \"just right\".\n",
    "\n",
    "Think about the impact of the:\n",
    "* temperature\n",
    "* model\n",
    "* max_tokens\n",
    "* assistant instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chat_args = {\n",
    "    'temperature': 0.5,\n",
    "    'model': 'gpt-3.5-turbo',\n",
    "    'max_tokens': 1000,\n",
    "}\n",
    "\n",
    "location = \"\"\n",
    "assistant_instructions = \"You are a helpful assistant.\"\n",
    "long_message = f\"\"\"\n",
    "Tell me about {location}.\n",
    "\"\"\"\n",
    "\n",
    "# build our messages to send to openAI.  These should be well formed JSON with a ROLE and CONTENT\n",
    "system_message = {\"role\":\"system\", \"content\": assistant_instructions}\n",
    "user_message = {\"role\":\"user\", \"content\": long_message}\n",
    "\n",
    "# we put these together into a single python list for processing together.\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "summary_response = simple_chat(messages=messages, **simple_chat_args)\n",
    "\n",
    "show_response_detail(summary_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine your prompt to include instruction, input data, and output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chat_args = {\n",
    "    'temperature': 0.5,\n",
    "    'model': 'gpt-3.5-turbo',\n",
    "    'max_tokens': 3000,\n",
    "}\n",
    "\n",
    "location = \"\"\n",
    "assistant_instructions = \"You are a helpful assistant.\"\n",
    "\n",
    "long_message = f\"\"\"\n",
    "Tell me about {location}.\n",
    "\"\"\"\n",
    "\n",
    "# build our messages to send to openAI.  These should be well formed JSON with a ROLE and CONTENT\n",
    "system_message = {\"role\":\"system\", \"content\": assistant_instructions}\n",
    "user_message = {\"role\":\"user\", \"content\":long_message}\n",
    "\n",
    "# we put these together into a single python list for processing together.\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "summary_response = simple_chat(messages=messages, **simple_chat_args)\n",
    "\n",
    "show_response_detail(summary_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it all together - Instruction, Input Data, Context, and Formatting.\n",
    "- Break your instructions into smaller pieces.\n",
    "- Take a few shots at how you would like things to work.\n",
    "- Give format instructions.\n",
    "- Add leading text.\n",
    "\n",
    "Experiment a few times with different models, temperatures, and max_tokens.  Also, try adjusting the system instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chat_args = {\n",
    "    'temperature': 0.5,\n",
    "    'model': 'gpt-3.5-turbo',\n",
    "    # 'model': 'gpt-4',\n",
    "    'max_tokens': 3000,\n",
    "}\n",
    "\n",
    "location = \"Tucson, Arizona\"\n",
    "assistant_instructions = \"You are a helpful assistant.\"\n",
    "\n",
    "long_message = f\"\"\"\n",
    "Tell me about {location}.\n",
    "\"\"\"\n",
    "\n",
    "# build our messages to send to openAI.  These should be well formed JSON with a ROLE and CONTENT\n",
    "system_message = {\"role\":\"system\", \"content\": assistant_instructions}\n",
    "user_message = {\"role\":\"user\", \"content\":long_message}\n",
    "\n",
    "# we put these together into a single python list for processing together.\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "summary_response = simple_chat(messages=messages, **simple_chat_args)\n",
    "\n",
    "show_response_detail(summary_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment a few times with different models, temperatures, and max_tokens.  Also, try adjusting the system instructions.\n",
    "\n",
    "For advanced python users - write a loop to repeat the process for different locations and output the results to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
