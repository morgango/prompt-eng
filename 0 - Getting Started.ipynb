{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from icecream import ic\n",
    "\n",
    "# load our environment file\n",
    "load_dotenv()\n",
    "\n",
    "# define our API Key\n",
    "openai.api_key = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0 - Support Functions\n",
    "\n",
    "A valid message for OpenAI has two features\n",
    "1. It is valid JSON.\n",
    "1. It has a \"role\".\n",
    "1. It has a \"message\".\n",
    "\n",
    "We can check this with `is_valid_message`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "def is_valid_message(message: Dict[str, Any]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a single message dictionary has the correct format to be sent to OpenAI.\n",
    "\n",
    "    Args:\n",
    "        message (Dict[str, Any]): A message dictionary with 'role' (str) and 'content' (str) keys.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the message is in the correct format, False otherwise.\n",
    "    \"\"\"\n",
    "    # Check if the message dictionary has 'role' and 'content' keys of the correct types.\n",
    "    if isinstance(message, dict) and 'role' in message and 'content' in message:\n",
    "        if isinstance(message['role'], str) and isinstance(message['content'], str):\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very common to have to check multiple messages, not just one.\n",
    "\n",
    "We can check them all with `are_valid_messages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_valid_messages(messages: List[Dict[str, Any]]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a list of messages is in the correct format to be sent to OpenAI.\n",
    "\n",
    "    Args:\n",
    "        messages (List[Dict[str, Any]]): A list of message dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all messages are in the correct format, False otherwise.\n",
    "    \"\"\"\n",
    "    return all(is_valid_message(message) for message in messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most chat interactions have a few parts:\n",
    "1.  A list of messages to be processed together.\n",
    "1. An ID for the openAI model to be used.\n",
    "1. How creattive you want the generation to be.\n",
    "1. The maximum number of tokens you want to use.\n",
    "\n",
    "We encapsulate this in `simple_chat`, and get back a JSON object with a number of different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_chat(messages: List[Dict[str, Any]], model: str = 'gpt-3.5-turbo', temperature: float = 0.9, max_tokens: int = 1024) -> str:\n",
    "    \"\"\"\n",
    "    Conduct a simple chat conversation using OpenAI's GPT-3 model.\n",
    "\n",
    "    Args:\n",
    "        messages (List[Dict[str, Any]]): A list of message dictionaries, where each dictionary contains a 'role' (str)\n",
    "            and 'content' (str) key-value pair representing the role of the message sender (e.g., 'system', 'user', 'assistant')\n",
    "            and the content of the message.\n",
    "        model (str, optional): The OpenAI model to use (default is 'gpt-3.5-turbo').\n",
    "        temperature (float, optional): Controls the randomness of the response. Higher values (e.g., 0.9) make the output more random,\n",
    "            while lower values (e.g., 0.2) make it more deterministic. Default is 0.9.\n",
    "        max_tokens (int, optional): The maximum length of the response, measured in tokens. Default is 1024 tokens.\n",
    "\n",
    "    Returns:\n",
    "        str: The response generated by the GPT-3 model.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input messages are not in the correct format.\n",
    "\n",
    "    Example:\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': 'What's the weather like today?'},\n",
    "        ]\n",
    "        response = simple_chat(messages)\n",
    "        print(response)  # Print the generated response.\n",
    "    \"\"\"\n",
    "\n",
    "    if not messages:\n",
    "        raise ValueError(\"Input messages list cannot be empty.\")\n",
    "\n",
    "    # Check if all messages are in the correct format.\n",
    "    if not are_valid_messages(messages):\n",
    "        raise ValueError(\"Input messages must be in the format [{'role': str, 'content': str}, ...]\")\n",
    "\n",
    "    # Send the messages to OpenAI and get the response\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be very useful to look at the actual details of the response.\n",
    "\n",
    "`show_response_detail` is a convienience function that outputs the details to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_response_detail(response: openai.openai_object.OpenAIObject):\n",
    "    \"\"\"\n",
    "    Extracts and displays details of the first message choice from an OpenAI response object.\n",
    "\n",
    "    This function is designed to work with response objects returned by OpenAI's language models,\n",
    "    specifically with choices that contain messages with 'role' and 'content' attributes.\n",
    "\n",
    "    Args:\n",
    "        response (openai.openai_object.OpenAIObject): The OpenAI response object containing message choices.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Example:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            prompt=\"Translate the following English text to French: 'Hello, world.'\"\n",
    "        )\n",
    "        response_detail(response)\n",
    "    \"\"\"\n",
    "    \n",
    "    ic({response.choices[0].message.role})\n",
    "    ic({response.choices[0].message.content})\n",
    "    ic({response.usage.prompt_tokens})\n",
    "    ic({response.usage.completion_tokens})\n",
    "    ic({response.usage.total_tokens})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0 - Example 1\n",
    "\n",
    "## Summarizing a Message\n",
    "\n",
    "A good job for Generative AI is generating text.  Here is a code example of exactly how you can do this with OpenAI.\n",
    "\n",
    "** Notes **\n",
    "\n",
    "1. We are using two different roles to definte the messages.\n",
    "1. The response object contains a lot of interesting information in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.openai_object.OpenAIObject'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8DIJ1BLXDcg6q7PSzY5e37DtLw07x at 0x107be6390> JSON: {\n",
       "  \"id\": \"chatcmpl-8DIJ1BLXDcg6q7PSzY5e37DtLw07x\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1698179323,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Jupiter is the largest planet in our Solar System and the fifth planet from the Sun. It is a gas giant with a mass that is one-thousandth that of the Sun, but it is two-and-a-half times more massive than all the other planets combined. Jupiter has been known to ancient civilizations since ancient times and is named after the Roman god Jupiter. It is one of the brightest objects in the night sky and can be seen with the naked eye. Its brightness is sometimes strong enough to cast visible shadows, and it is typically the third-brightest natural object in the night sky, only after the Moon and Venus.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 149,\n",
       "    \"completion_tokens\": 127,\n",
       "    \"total_tokens\": 276\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_message = \"\"\"Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter. When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows, and is on average the third-brightest natural object in the night sky after the Moon and Venus.\"\"\"\n",
    "\n",
    "# build our messages to send to openAI.  These should be well formed JSON with a ROLE and CONTENT\n",
    "# system_message = {\"role\":\"system\", \"content\":\"Summarize content you are provided in 1 sentence.\"}\n",
    "system_message = {\"role\":\"system\", \"content\":\"Summarize content you are provided.\"}\n",
    "user_message = {\"role\":\"user\", \"content\":long_message}\n",
    "\n",
    "summary_response = simple_chat(messages=[system_message, user_message])\n",
    "summary_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| {response.choices[0].message.role}: {'assistant'}\n",
      "ic| {response.choices[0].message.content}: {'Jupiter is the largest planet in our Solar System and the fifth planet from '\n",
      "                                            'the Sun. It is a gas giant with a mass that is one-thousandth that of the '\n",
      "                                            'Sun, but it is two-and-a-half times more massive than all the other planets '\n",
      "                                            'combined. Jupiter has been known to ancient civilizations since ancient '\n",
      "                                            'times and is named after the Roman god Jupiter. It is one of the brightest '\n",
      "                                            'objects in the night sky and can be seen with the naked eye. Its brightness '\n",
      "                                            'is sometimes strong enough to cast visible shadows, and it is typically the '\n",
      "                                            'third-brightest natural object in the night sky, only after the Moon and '\n",
      "                                            'Venus.'}\n",
      "ic| {response.usage.prompt_tokens}: {149}\n",
      "ic| {response.usage.completion_tokens}: {127}\n",
      "ic| {response.usage.total_tokens}: {276}\n"
     ]
    }
   ],
   "source": [
    "show_response_detail(summary_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.openai_object.OpenAIObject'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8DILPFUelHN5XlQryE8OQYkjKzDxB at 0x1075649a0> JSON: {\n",
       "  \"id\": \"chatcmpl-8DILPFUelHN5XlQryE8OQYkjKzDxB\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1698179471,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Here's a Python function that will print out the most useful parts of a response object from OpenAI's GPT-3 API:\\n\\n```python\\ndef print_useful_info(response):\\n    print(\\\"Response Status Code:\\\", response.status_code)\\n    print(\\\"Response Headers:\\\", response.headers)\\n    print(\\\"Response JSON:\\\", response.json())\\n```\\n\\nThis function takes a response object as an argument and prints out the following useful information:\\n\\n1. Response Status Code: The HTTP status code returned by the API. It indicates whether the request was successful or if there was an error.\\n\\n2. Response Headers: The headers returned by the API. Headers contain additional information about the response, such as Content-Type, Content-Length, etc.\\n\\n3. Response JSON: The JSON data returned by the API. This contains the actual response from the API, which may include the generated text or any error messages.\\n\\nYou can call this function and pass your response object to print out these details. Make sure you have imported the necessary libraries (e.g., `import requests`) to use the response object.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 26,\n",
       "    \"completion_tokens\": 215,\n",
       "    \"total_tokens\": 241\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_message = \"Write a python function that will print out the most useful parts of a response object from OpenAI\"\n",
    "user_message = {\"role\":\"user\", \"content\":long_message}\n",
    "\n",
    "code_response = simple_chat(messages=[user_message])\n",
    "code_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| {response.choices[0].message.role}: {'assistant'}\n",
      "ic| {response.choices[0].message.content}: {\"Here's a Python function that will print out the most useful parts of a \"\n",
      "                                            \"response object from OpenAI's GPT-3 API:\n",
      "                                           \"\n",
      "                                            '\n",
      "                                           '\n",
      "                                            '```python\n",
      "                                           '\n",
      "                                            'def print_useful_info(response):\n",
      "                                           '\n",
      "                                            '    print(\"Response Status Code:\", response.status_code)\n",
      "                                           '\n",
      "                                            '    print(\"Response Headers:\", response.headers)\n",
      "                                           '\n",
      "                                            '    print(\"Response JSON:\", response.json())\n",
      "                                           '\n",
      "                                            '```\n",
      "                                           '\n",
      "                                            '\n",
      "                                           '\n",
      "                                            'This function takes a response object as an argument and prints out the '\n",
      "                                            'following useful information:\n",
      "                                           '\n",
      "                                            '\n",
      "                                           '\n",
      "                                            '1. Response Status Code: The HTTP status code returned by the API. It '\n",
      "                                            'indicates whether the request was successful or if there was an error.\n",
      "                                           '\n",
      "                                            '\n",
      "                                           '\n",
      "                                            '2. Response Headers: The headers returned by the API. Headers contain '\n",
      "                                            'additional information about the response, such as Content-Type, '\n",
      "                                            'Content-Length, etc.\n",
      "                                           '\n",
      "                                            '\n",
      "                                           '\n",
      "                                            '3. Response JSON: The JSON data returned by the API. This contains the '\n",
      "                                            'actual response from the API, which may include the generated text or any '\n",
      "                                            'error messages.\n",
      "                                           '\n",
      "                                            '\n",
      "                                           '\n",
      "                                            'You can call this function and pass your response object to print out these '\n",
      "                                            'details. Make sure you have imported the necessary libraries (e.g., `import '\n",
      "                                            'requests`) to use the response object.'}\n",
      "ic| {response.usage.prompt_tokens}: {26}\n",
      "ic| {response.usage.completion_tokens}: {215}\n",
      "ic| {response.usage.total_tokens}: {241}\n"
     ]
    }
   ],
   "source": [
    "show_response_detail(code_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
