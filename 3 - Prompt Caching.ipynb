{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_llm_cache import ElasticsearchLLMCache\n",
    "from elasticsearch.exceptions import NotFoundError\n",
    "\n",
    "# common libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from icecream import ic\n",
    "\n",
    "# load our environment file\n",
    "load_dotenv()\n",
    "\n",
    "es_url = f\"https://{os.environ['elasticsearch_user']}:{os.environ['elasticsearch_pw']}@{os.environ['elasticsearch_host']}:{os.environ['elasticsearch_port']}\"\n",
    "# es_index= os.environ['elasticsearch_index']\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['openai_api_key']\n",
    "open_api_key=os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# define our API Key\n",
    "openai.api_key = os.getenv(\"openai_api_key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:GET https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3 [status:200 duration:0.135s]\n",
      "ic| f'{model_id} exists.': 'sentence-transformers__msmarco-minilm-l-12-v3 exists.'\n",
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test [status:200 duration:0.035s]\n",
      "ic| f'{index_name} exists.': 'llm_cache_test exists.'\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch([es_url])\n",
    "\n",
    "index_name = 'llm_cache_test'\n",
    "# model_id = '.elser_model_1'\n",
    "model_id = 'sentence-transformers__msmarco-minilm-l-12-v3'\n",
    "\n",
    "if es.ml.get_trained_models(model_id=model_id):\n",
    "    ic(f'{model_id} exists.')\n",
    "else:\n",
    "    ic(f'{model_id} does not exist.')\n",
    "\n",
    "if es.indices.exists(index=index_name):\n",
    "    ic(f'{index_name} exists.')\n",
    "else:\n",
    "    ic(f'{index_name} does not exist.')\n",
    "    es.indices.create(index= index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test [status:200 duration:0.035s]\n",
      "ic| f'{index_name} exists.': 'llm_cache_test exists.'\n",
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test [status:200 duration:0.034s]\n",
      "INFO:elasticsearch_llm_cache:Index llm_cache_test already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<elasticsearch_llm_cache.ElasticsearchLLMCache at 0x10795ac90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "#print(os.environ['ELASTIC_CLOUD_ID'])\n",
    "#time.sleep(10)\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from elasticsearch_llm_cache import (\n",
    "    ElasticsearchLLMCache,  # Import the class from the file\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "es_client = es\n",
    "\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    ic(f'{index_name} exists.')\n",
    "else:\n",
    "    ic(f'{index_name} does not exist.')\n",
    "    es_client.indices.create(index= index_name)\n",
    "\n",
    "\n",
    "# Initialize your caching class\n",
    "cache = ElasticsearchLLMCache(es_client=es_client, index_name=index_name, es_model_id=model_id, create_index=False)\n",
    "cache.create_index(dims=768)\n",
    "cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test/_search [status:200 duration:0.050s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test/_update/1TtWtYsBIWOTmRMzt2aa [status:200 duration:0.039s]\n",
      "ic| f\"Cache hit: {llm_response['response']}\": 'Cache hit: [\"I\\'m here to assist you!\"]'\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello, how can I help?\"\n",
    "llm_response = cache.query(prompt_text=prompt, )\n",
    "\n",
    "# If no cache hit, add new response to cache\n",
    "if llm_response:\n",
    "    ic(f\"Cache hit: {llm_response['response']}\")\n",
    "else:\n",
    "    llm_response = \"I'm here to assist you!\"  # Assume this response is fetched from LLM\n",
    "    cache.add(prompt=prompt, response=llm_response)\n",
    "    ic(f\"Cache add: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 21:17:00,295 INFO : Establishing connection to Elasticsearch\n",
      "2023-11-08 21:17:00,432 INFO : Connected to cluster named '4dadf200942c4f3fb6113618e49a559c' (version: 8.11.0)\n",
      "2023-11-08 21:17:00,432 INFO : Loading HuggingFace transformer tokenizer and model 'sentence-transformers/msmarco-MiniLM-L-12-v3'\n",
      "Downloading (…)okenizer_config.json: 100%|█████| 432/432 [00:00<00:00, 1.02MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█████| 629/629 [00:00<00:00, 9.52MB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███| 232k/232k [00:00<00:00, 5.64MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████| 112/112 [00:00<00:00, 424kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|███| 466k/466k [00:00<00:00, 6.47MB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████| 134M/134M [00:08<00:00, 15.1MB/s]\n",
      "Downloading (…)abaf1/.gitattributes: 100%|█████| 736/736 [00:00<00:00, 5.49MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|█████| 190/190 [00:00<00:00, 1.46MB/s]\n",
      "Downloading (…)2f517abaf1/README.md: 100%|█| 3.69k/3.69k [00:00<00:00, 16.5MB/s]\n",
      "Downloading (…)517abaf1/config.json: 100%|█████| 629/629 [00:00<00:00, 3.57MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████| 122/122 [00:00<00:00, 847kB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████| 134M/134M [00:08<00:00, 16.6MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|████| 53.0/53.0 [00:00<00:00, 414kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████| 112/112 [00:00<00:00, 773kB/s]\n",
      "Downloading (…)abaf1/tokenizer.json: 100%|███| 466k/466k [00:00<00:00, 5.46MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|█████| 432/432 [00:00<00:00, 1.94MB/s]\n",
      "Downloading (…)2f517abaf1/vocab.txt: 100%|███| 232k/232k [00:00<00:00, 6.22MB/s]\n",
      "Downloading (…)17abaf1/modules.json: 100%|█████| 229/229 [00:00<00:00, 1.03MB/s]\n",
      "2023-11-08 21:17:24,756 INFO : Creating model with id 'sentence-transformers__msmarco-minilm-l-12-v3'\n",
      "2023-11-08 21:17:24,829 INFO : Uploading model definition\n",
      "100%|█████████████████████████████████████| 127/127 [00:33<00:00,  3.79 parts/s]\n",
      "2023-11-08 21:17:58,354 INFO : Uploading model vocabulary\n",
      "2023-11-08 21:17:58,490 INFO : Model successfully imported with id 'sentence-transformers__msmarco-minilm-l-12-v3'\n"
     ]
    }
   ],
   "source": [
    "!eland_import_hub_model --url \"$es_url\" \\\n",
    "      --hub-model-id \"sentence-transformers/msmarco-MiniLM-L-12-v3\" \\\n",
    "      --task-type \"text_embedding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
