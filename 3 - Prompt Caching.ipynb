{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_llm_cache import ElasticsearchLLMCache, ElasticsearchLLMFilter\n",
    "from elasticsearch.exceptions import NotFoundError\n",
    "\n",
    "# common libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from icecream import ic\n",
    "\n",
    "# load our environment file\n",
    "load_dotenv()\n",
    "\n",
    "es_url = f\"https://{os.environ['elasticsearch_user']}:{os.environ['elasticsearch_pw']}@{os.environ['elasticsearch_host']}:{os.environ['elasticsearch_port']}\"\n",
    "# es_index= os.environ['elasticsearch_index']\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['openai_api_key']\n",
    "open_api_key=os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# define our API Key\n",
    "openai.api_key = os.getenv(\"openai_api_key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([es_url])\n",
    "\n",
    "cache_index_name = 'llm_cache_test'\n",
    "filter_index_name = 'llm_filter_test'\n",
    "model_id = 'sentence-transformers__msmarco-minilm-l-12-v3'\n",
    "\n",
    "# if es.ml.get_trained_models(model_id=model_id):\n",
    "#     ic(f'{model_id} exists.')\n",
    "# else:\n",
    "#     ic(f'{model_id} does not exist.')\n",
    "\n",
    "# if es.indices.exists(index=cache_index_name):\n",
    "#     ic(f'{cache_index_name} exists.')\n",
    "# else:\n",
    "#     ic(f'{cache_index_name} does not exist.')\n",
    "#     es.indices.create(index=cache_index_name)\n",
    "\n",
    "# if es.indices.exists(index=filter_index_name):\n",
    "#     ic(f'{filter_index_name} exists.')\n",
    "# else:\n",
    "#     ic(f'{filter_index_name} does not exist.')\n",
    "#     es.indices.create(index=filter_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test [status:200 duration:0.644s]\n",
      "INFO:elastic_transport.transport:DELETE https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test [status:200 duration:0.101s]\n",
      "ic| f'{cache_index_name} exists, deleting.': 'llm_cache_test exists, deleting.'\n",
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test [status:200 duration:0.034s]\n",
      "INFO:elastic_transport.transport:DELETE https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test [status:200 duration:0.096s]\n",
      "ic| f'{filter_index_name} exists, deleting.': 'llm_filter_test exists, deleting.'\n",
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test [status:404 duration:0.032s]\n",
      "INFO:elastic_transport.transport:PUT https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache_test [status:200 duration:0.151s]\n",
      "ic| f\"Index {self.index_name} created with {self.dims} dimensions.\": 'Index llm_cache_test created with 384 dimensions.'\n",
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test [status:404 duration:0.032s]\n",
      "INFO:elastic_transport.transport:PUT https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test [status:200 duration:0.144s]\n",
      "ic| f\"Index {self.index_name} created with {self.dims} dimensions.\": 'Index llm_filter_test created with 384 dimensions.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cache_index': 'llm_filter_test', 'created_new': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "#print(os.environ['ELASTIC_CLOUD_ID'])\n",
    "#time.sleep(10)\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from elasticsearch_llm_cache import (\n",
    "    ElasticsearchLLMCache,  \n",
    "    ElasticsearchLLMFilter,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "es_client = es\n",
    "\n",
    "if es_client.indices.exists(index=cache_index_name):\n",
    "    es_client.indices.delete(index=cache_index_name)\n",
    "    ic(f'{cache_index_name} exists, deleting.')\n",
    "\n",
    "if es_client.indices.exists(index=filter_index_name):\n",
    "    es_client.indices.delete(index=filter_index_name)\n",
    "    ic(f'{filter_index_name} exists, deleting.')\n",
    "\n",
    "# es_client.indices.create(index=cache_index_name)\n",
    "# es_client.indices.create(index=filter_index_name)\n",
    "\n",
    "\n",
    "# Initialize your caching class\n",
    "cache = ElasticsearchLLMCache(es_client=es_client, index_name=cache_index_name, es_model_id=model_id, create_index=False)\n",
    "cache.create_index(dims=384)\n",
    "\n",
    "filter = ElasticsearchLLMFilter(es_client=es_client, index_name=filter_index_name, es_model_id=model_id, create_index=False)\n",
    "filter.create_index(dims=384)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.493s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.036s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7896] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [0.5523583, 0.0223902, 0.42353424, -0.35227466, -0.3553125, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.034s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.038s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7896] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [0.34790492, 0.14997636, -0.55026966, 0.2960562, -0.39075863, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.034s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.037s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7912] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [0.429899, -0.26816878, 0.19983439, -0.6330846, 0.15662163, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.034s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.037s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.035s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7904] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [0.51504606, -0.28797817, 0.029313475, -0.50705004, -0.29441717, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.034s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.037s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7918] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [0.5499592, -0.2055945, 0.111300595, -0.2723482, 0.27548346, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.034s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.036s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7916] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [0.5936062, 0.0039967373, 0.35754645, -0.071133204, -0.6296767, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.033s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.038s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7880] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [-0.22559051, 0.09176764, 0.043280154, 0.65022063, -0.61777896, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.036s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7905] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [0.2115622, -0.09020161, 0.59510946, 0.15204342, -0.009849593, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.035s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7884] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [-0.48996997, 0.1585888, -0.17853254, 0.3564283, -0.29202995, ...]')\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.062s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.034s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.035s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_doc [status:400 duration:0.037s]\n",
      "ERROR:elasticsearch_llm_cache:BadRequestError(400, 'document_parsing_exception', '[1:7930] failed to parse: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [-0.45813465, -0.33919775, 0.1406398, -0.41472045, 0.5685599, ...]')\n"
     ]
    }
   ],
   "source": [
    "# filter.clear()\n",
    "subjects = ['sports', 'money', 'celebrities', 'basketball', 'soccer', 'tennis', 'skiing', 'animals', 'snakes', 'software development']\n",
    "filter_contents = []\n",
    "\n",
    "for subject in subjects:\n",
    "    filter.add(prompt=subject, response=f\"Sorry, I can't talk about {subject}.\")\n",
    "\n",
    "# for subject in subjects:\n",
    "#     filter_contents.append({'prompt': subject, 'response': f\"Sorry, I can't talk about {subject}.\"})\n",
    "\n",
    "\n",
    "# filter_results = filter.add_bulk(documents=filter_contents)\n",
    "# filter.list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prompt_text: 'How do I code a linked list with python?'\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.037s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.035s]\n",
      "ic| results: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = filter.query(prompt_text=\"How do I code a linked list with python?\", similarity_threshold=0.2, size=1)\n",
    "ic(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prompt_text: 'I will vote for a democratic politician'\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer [status:200 duration:0.036s]\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_filter_test/_search [status:200 duration:0.033s]\n",
      "ic| results: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter.query('I will vote for a democratic politician', similarity_threshold=0.25)\n",
    "ic(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hello, my name is Morgan?\"\n",
    "llm_response = \"I'm here to assist you!\"  # Assume this response is fetched from LLM\n",
    "\n",
    "cache_contents = [\n",
    "    {\"prompt\": \"Hello, my name is Morgan\", \"response\": \"Hi Morgan\"},\n",
    "    {\"prompt\": \"Hello, my name is Adam\", \"response\": \"Hi Adam\"},\n",
    "    {\"prompt\": \"Hello, my name is David\", \"response\": \"Hi David\"},\n",
    "    {\"prompt\": \"Hello, my name is Morgan\", \"response\": \"Hi Morgan\"},\n",
    "]\n",
    "\n",
    "cache_results = cache.add_bulk(documents=cache_contents)\n",
    "\n",
    "for item in cache_contents:\n",
    "    llm_response = cache.query(prompt_text=item['prompt'], )\n",
    "    ic(llm_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eland_import_hub_model --url \"$es_url\" \\\n",
    "      --hub-model-id \"sentence-transformers/msmarco-MiniLM-L-12-v3\" \\\n",
    "      --task-type \"text_embedding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-17 12:57:06,650 INFO : Establishing connection to Elasticsearch\n",
      "2023-11-17 12:57:06,972 INFO : Connected to cluster named '4dadf200942c4f3fb6113618e49a559c' (version: 8.11.0)\n",
      "2023-11-17 12:57:06,976 INFO : Loading HuggingFace transformer tokenizer and model 'valhalla/distilbart-mnli-12-6'\n",
      "/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:239: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:246: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
      "/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:278: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:936: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1:\n",
      "/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1559: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  if len(torch.unique_consecutive(eos_mask.sum(1))) > 1:\n",
      "2023-11-17 12:57:34,804 INFO : Creating model with id 'valhalla__distilbart-mnli-12-6'\n",
      "2023-11-17 12:57:34,883 INFO : Uploading model definition\n",
      "100%|███████████████████████████████████| 1170/1170 [04:47<00:00,  4.07 parts/s]\n",
      "2023-11-17 13:02:23,320 INFO : Uploading model vocabulary\n",
      "2023-11-17 13:02:24,113 INFO : Model successfully imported with id 'valhalla__distilbart-mnli-12-6'\n"
     ]
    }
   ],
   "source": [
    "!eland_import_hub_model --url \"$es_url\" \\\n",
    "      --hub-model-id \"valhalla/distilbart-mnli-12-6\" \\\n",
    "      --task-type \"zero_shot_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-17 12:30:43,902 INFO : Establishing connection to Elasticsearch\n",
      "2023-11-17 12:30:44,280 INFO : Connected to cluster named '4dadf200942c4f3fb6113618e49a559c' (version: 8.11.0)\n",
      "2023-11-17 12:30:44,281 INFO : Loading HuggingFace transformer tokenizer and model 'distilbert-base-uncased-finetuned-sst-2-english'\n",
      "Downloading tokenizer_config.json: 100%|█████| 48.0/48.0 [00:00<00:00, 74.6kB/s]\n",
      "Downloading config.json: 100%|█████████████████| 629/629 [00:00<00:00, 5.43MB/s]\n",
      "Downloading vocab.txt: 100%|█████████████████| 232k/232k [00:00<00:00, 2.38MB/s]\n",
      "Downloading model.safetensors: 100%|█████████| 268M/268M [00:04<00:00, 60.9MB/s]\n",
      "/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
      "2023-11-17 12:31:17,624 INFO : Creating model with id 'distilbert-base-uncased-finetuned-sst-2-english'\n",
      "2023-11-17 12:31:17,685 INFO : Uploading model definition\n",
      "100%|█████████████████████████████████████| 256/256 [00:53<00:00,  4.75 parts/s]\n",
      "2023-11-17 12:32:11,576 INFO : Uploading model vocabulary\n",
      "2023-11-17 12:32:11,730 INFO : Starting model deployment\n",
      "2023-11-17 12:32:18,205 INFO : Model successfully imported with id 'distilbert-base-uncased-finetuned-sst-2-english'\n"
     ]
    }
   ],
   "source": [
    "!eland_import_hub_model --url \"$es_url\" \\\n",
    "      --hub-model-id \"distilbert-base-uncased-finetuned-sst-2-english\" \\\n",
    "      --task-type \"text_classification\" \\\n",
    "      --start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:GET https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models [status:200 duration:0.354s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".elser_model_1\n",
      ".elser_model_2\n",
      "distilbert-base-uncased-finetuned-sst-2-english\n",
      "elastic__distilbert-base-uncased-finetuned-conll03-english\n",
      "lang_ident_model_1\n",
      "sentence-transformers__all-distilroberta-v1\n",
      "sentence-transformers__msmarco-minilm-l-12-v3\n",
      "valhalla__distilbart-mnli-12-6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/distilbert-base-uncased-finetuned-sst-2-english/_infer [status:200 duration:0.813s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'predicted_value': 'POSITIVE', 'prediction_probability': 0.9997331448853626}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient\n",
    "\n",
    "models = MlClient.get_trained_models(es_client)\n",
    "for model in models[\"trained_model_configs\"]:\n",
    "    print(model[\"model_id\"])\n",
    "\n",
    "\n",
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "#Run a query againt the model - this is the format the query imput must be used in, you can later map your features into this format through an ingest pipeline\n",
    "doc_test = {\"text_field\": \"This is a very nice sentence\"}\n",
    "\n",
    "result = MlClient.infer_trained_model(es, model_id =model_id, docs = doc_test)\n",
    "result[\"inference_results\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/valhalla__distilbart-mnli-12-6/_infer [status:200 duration:0.375s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3 - Prompt Caching.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   filtered_results \u001b[39m=\u001b[39m [sub_item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m result \u001b[39mfor\u001b[39;00m sub_item \u001b[39min\u001b[39;00m item[\u001b[39m'\u001b[39m\u001b[39mtop_classes\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m sub_item[\u001b[39m'\u001b[39m\u001b[39mclass_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m threshold]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m filtered_results\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mfilter\u001b[39;49m(es\u001b[39m=\u001b[39;49mes, text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mOur city councilman is going to be at the event.\u001b[39;49m\u001b[39m\"\u001b[39;49m, labels\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39msports\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmoney\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfamily\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpolitics\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m res\n",
      "\u001b[1;32m/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3 - Prompt Caching.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m inference_config \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mzero_shot_classification\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m: labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mmulti_label\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m result \u001b[39m=\u001b[39m MlClient\u001b[39m.\u001b[39minfer_trained_model(es, model_id \u001b[39m=\u001b[39mmodel_id, docs \u001b[39m=\u001b[39m doc_test, inference_config\u001b[39m=\u001b[39minference_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m filtered_results \u001b[39m=\u001b[39m [sub_item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m result \u001b[39mfor\u001b[39;00m sub_item \u001b[39min\u001b[39;00m item[\u001b[39m'\u001b[39m\u001b[39mtop_classes\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m sub_item[\u001b[39m'\u001b[39m\u001b[39mclass_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m threshold]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m filtered_results\n",
      "\u001b[1;32m/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3 - Prompt Caching.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m inference_config \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mzero_shot_classification\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m: labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mmulti_label\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m result \u001b[39m=\u001b[39m MlClient\u001b[39m.\u001b[39minfer_trained_model(es, model_id \u001b[39m=\u001b[39mmodel_id, docs \u001b[39m=\u001b[39m doc_test, inference_config\u001b[39m=\u001b[39minference_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m filtered_results \u001b[39m=\u001b[39m [sub_item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m result \u001b[39mfor\u001b[39;00m sub_item \u001b[39min\u001b[39;00m item[\u001b[39m'\u001b[39;49m\u001b[39mtop_classes\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mif\u001b[39;00m sub_item[\u001b[39m'\u001b[39m\u001b[39mclass_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m threshold]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m filtered_results\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient\n",
    "\n",
    "def filter(text, labels, es, model_id = \"valhalla__distilbart-mnli-12-6\", threshold = 0.9):\n",
    "\n",
    "  doc_test = {\"text_field\": text}\n",
    "  inference_config = {\n",
    "      \"zero_shot_classification\": {\n",
    "        \"labels\": labels,\n",
    "        \"multi_label\": True\n",
    "      }\n",
    "    }\n",
    "\n",
    "  result = MlClient.infer_trained_model(es, model_id =model_id, docs = doc_test, inference_config=inference_config)\n",
    "\n",
    "  filtered_results = [sub_item for item in result for sub_item in item['top_classes'] if sub_item['class_score'] > threshold]\n",
    "\n",
    "  return filtered_results\n",
    "\n",
    "res = filter(es=es, text=\"Our city councilman is going to be at the event.\", labels=[\"sports\", \"money\", \"family\", \"politics\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'politics',\n",
       "  'class_probability': 0.988533928117081,\n",
       "  'class_score': 0.988533928117081}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
