{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_llm_cache import ElasticsearchLLMCache, ElasticsearchLLMFilter\n",
    "from elasticsearch.exceptions import NotFoundError\n",
    "\n",
    "# common libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from icecream import ic\n",
    "\n",
    "# load our environment file\n",
    "load_dotenv()\n",
    "\n",
    "es_url = f\"https://{os.environ['elasticsearch_user']}:{os.environ['elasticsearch_pw']}@{os.environ['elasticsearch_host']}:{os.environ['elasticsearch_port']}\"\n",
    "# es_index= os.environ['elasticsearch_index']\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['openai_api_key']\n",
    "open_api_key=os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# define our API Key\n",
    "openai.api_key = os.getenv(\"openai_api_key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([es_url])\n",
    "\n",
    "cache_index_name = 'llm_cache_test'\n",
    "filter_index_name = 'llm_filter_test'\n",
    "model_id = 'sentence-transformers__msmarco-minilm-l-12-v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "#print(os.environ['ELASTIC_CLOUD_ID'])\n",
    "#time.sleep(10)\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from elasticsearch_llm_cache import (\n",
    "    ElasticsearchLLMCache,  \n",
    "    ElasticsearchLLMFilter,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "es_client = es\n",
    "\n",
    "if es_client.indices.exists(index=cache_index_name):\n",
    "    es_client.indices.delete(index=cache_index_name)\n",
    "    ic(f'{cache_index_name} exists, deleting.')\n",
    "\n",
    "if es_client.indices.exists(index=filter_index_name):\n",
    "    es_client.indices.delete(index=filter_index_name)\n",
    "    ic(f'{filter_index_name} exists, deleting.')\n",
    "\n",
    "# es_client.indices.create(index=cache_index_name)\n",
    "# es_client.indices.create(index=filter_index_name)\n",
    "\n",
    "\n",
    "# Initialize your caching class\n",
    "cache = ElasticsearchLLMCache(es_client=es_client, index_name=cache_index_name, es_model_id=model_id, create_index=False)\n",
    "cache.create_index(dims=384)\n",
    "\n",
    "filter = ElasticsearchLLMFilter(es_client=es_client, index_name=filter_index_name, es_model_id=model_id, create_index=False)\n",
    "filter.create_index(dims=384)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eland_import_hub_model --url \"$es_url\" \\\n",
    "      --hub-model-id \"sentence-transformers/msmarco-MiniLM-L-12-v3\" \\\n",
    "      --task-type \"text_embedding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Party fill-mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single label classification\n",
    "You provide some text and get back \"Positive\" or \"Negative\" and a probability of a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eland_import_hub_model --url \"$es_url\" \\\n",
    "      --hub-model-id \"distilbert-base-uncased-finetuned-sst-2-english\" \\\n",
    "      --task-type \"text_classification\" \\\n",
    "      --start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient\n",
    "\n",
    "\n",
    "def single_label_classify(text, es, model_id=\"distilbert-base-uncased-finetuned-sst-2-english\"):\n",
    "    models = MlClient.get_trained_models(es_client)\n",
    "    for model in models[\"trained_model_configs\"]:\n",
    "        print(model[\"model_id\"])\n",
    "\n",
    "\n",
    "    #Run a query againt the model - this is the format the query imput must be used in, you can later map your features into this format through an ingest pipeline\n",
    "    doc_test = {\"text_field\": text}\n",
    "\n",
    "    result = MlClient.infer_trained_model(es, model_id =model_id, docs = doc_test)\n",
    "    ic(result)\n",
    "    return result[\"inference_results\"]\n",
    "\n",
    "res = single_label_classify(es=es, text=\"This totally, totally, totally sucks\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Detection\n",
    "You provide some text and get back \"HATE\" or \"NON_HATE\" and a probability of a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eland_import_hub_model --url \"$es_url\" \\\n",
    "      --hub-model-id \"Hate-speech-CNERG/dehatebert-mono-english\" \\\n",
    "      --task-type \"text_classification\" \\\n",
    "      --start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient\n",
    "\n",
    "\n",
    "def hate_speech_classify(text, es, model_id=\"hate-speech-cnerg__dehatebert-mono-english\"):\n",
    "    models = MlClient.get_trained_models(es_client)\n",
    "    for model in models[\"trained_model_configs\"]:\n",
    "        print(model[\"model_id\"])\n",
    "\n",
    "\n",
    "    #Run a query againt the model - this is the format the query imput must be used in, you can later map your features into this format through an ingest pipeline\n",
    "    doc_test = {\"text_field\": text}\n",
    "\n",
    "    result = MlClient.infer_trained_model(es, model_id =model_id, docs = doc_test)\n",
    "    ic(result)\n",
    "    return result[\"inference_results\"]\n",
    "\n",
    "res = hate_speech_classify(es=es, text=\"This totally, totally, totally sucks\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot classification\n",
    "\n",
    "You provide some text and some labels that could potentially describe the text.\n",
    "This will return an array with all the labels that matched (class name) and the probability of the match.\n",
    "Optionally, you can provide a threshold where values lower than it will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eland_import_hub_model --url \"$es_url\" \\\n",
    "      --hub-model-id \"valhalla/distilbart-mnli-12-6\" \\\n",
    "      --task-type \"zero_shot_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient\n",
    "\n",
    "def zero_shot_classify(text, labels, es, model_id = \"valhalla__distilbart-mnli-12-6\", threshold = 0.5):\n",
    "\n",
    "  doc_test = {\"text_field\": text}\n",
    "  inference_config = {\n",
    "      \"zero_shot_classification\": {\n",
    "        \"labels\": labels,\n",
    "        \"multi_label\": True\n",
    "      }\n",
    "    }\n",
    "\n",
    "  result = MlClient.infer_trained_model(es, model_id =model_id, docs = doc_test, inference_config=inference_config)\n",
    "\n",
    "  filtered_results = {}\n",
    "\n",
    "  filtered_data = [item for item in result['inference_results'][0]['top_classes'] if item['class_probability'] >= threshold]\n",
    "\n",
    "  return filtered_data\n",
    "\n",
    "res = zero_shot_classify(es=es, text=\"Our city councilman is going to be at the event.\", labels=[\"sports\", \"money\", \"family\", \"politics\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = filter(es=es, text=\"Tell me about the plant that blooms and has petals\", labels=[\"sports\", \"money\", \"family\", \"flowers\", \"politics\"], threshold=0.75)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
