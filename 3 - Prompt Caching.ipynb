{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:GET https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/_ml/trained_models/.elser_model_1 [status:200 duration:0.118s]\n",
      "ic| f'{model_id} exists.': '.elser_model_1 exists.'\n",
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/cache [status:200 duration:0.036s]\n",
      "ic| f'{index_name} exists.': 'cache exists.'\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_llm_cache import ElasticsearchLLMCache\n",
    "from elasticsearch.exceptions import NotFoundError\n",
    "\n",
    "# common libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from icecream import ic\n",
    "\n",
    "# load our environment file\n",
    "load_dotenv()\n",
    "\n",
    "es_url = f\"https://{os.environ['elasticsearch_user']}:{os.environ['elasticsearch_pw']}@{os.environ['elasticsearch_host']}:{os.environ['elasticsearch_port']}\"\n",
    "# es_index= os.environ['elasticsearch_index']\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['openai_api_key']\n",
    "open_api_key=os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# define our API Key\n",
    "openai.api_key = os.getenv(\"openai_api_key\")\n",
    "\n",
    "es = Elasticsearch([es_url])\n",
    "\n",
    "index_name = 'cache'\n",
    "model_id = '.elser_model_1'\n",
    "\n",
    "if es.ml.get_trained_models(model_id=model_id):\n",
    "    ic(f'{model_id} exists.')\n",
    "else:\n",
    "    ic(f'{model_id} does not exist.')\n",
    "\n",
    "if es.indices.exists(index=index_name):\n",
    "    ic(f'{index_name} exists.')\n",
    "else:\n",
    "    ic(f'{index_name} does not exist.')\n",
    "    es.indices.create(index= index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:HEAD https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache [status:404 duration:0.045s]\n",
      "INFO:elastic_transport.transport:PUT https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache [status:200 duration:0.129s]\n",
      "INFO:elasticsearch_llm_cache:Index llm_cache created.\n",
      "INFO:elastic_transport.transport:POST https://demo-defc18.es.us-central1.gcp.cloud.es.io:9243/llm_cache/_search [status:404 duration:0.060s]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "NotFoundError(404, 'resource_not_found_exception', 'Could not find trained model [sentence-transformers__all-distilroberta-v1]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3 - Prompt Caching.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m llm_cache \u001b[39m=\u001b[39m ElasticsearchLLMCache(es)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Query the cache\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cache_response \u001b[39m=\u001b[39m llm_cache\u001b[39m.\u001b[39;49mquery(prompt_text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHello, how can I help?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# If no cache hit, add new response to cache\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morgan/Library/CloudStorage/Dropbox/me/prompt-eng/3%20-%20Prompt%20Caching.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cache_response:\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/me/prompt-eng/elasticsearch_llm_cache.py:174\u001b[0m, in \u001b[0;36mElasticsearchLLMCache.query\u001b[0;34m(self, prompt_text, similarity_threshold, num_candidates, create_date_gte)\u001b[0m\n\u001b[1;32m    146\u001b[0m knn \u001b[39m=\u001b[39m [\n\u001b[1;32m    147\u001b[0m     {\n\u001b[1;32m    148\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfield\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mprompt_vector\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     }\n\u001b[1;32m    167\u001b[0m ]\n\u001b[1;32m    169\u001b[0m fields \u001b[39m=\u001b[39m [\n\u001b[1;32m    170\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m ]\n\u001b[0;32m--> 174\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mes\u001b[39m.\u001b[39;49msearch(index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex_name,\n\u001b[1;32m    175\u001b[0m                       knn\u001b[39m=\u001b[39;49mknn,\n\u001b[1;32m    176\u001b[0m                       fields\u001b[39m=\u001b[39;49mfields,\n\u001b[1;32m    177\u001b[0m                       size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    178\u001b[0m                       source\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m                       )\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m resp[\u001b[39m'\u001b[39m\u001b[39mhits\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m {}\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:402\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m \u001b[39mreturn\u001b[39;00m api(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:3673\u001b[0m, in \u001b[0;36mElasticsearch.search\u001b[0;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version)\u001b[0m\n\u001b[1;32m   3671\u001b[0m \u001b[39mif\u001b[39;00m __body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3672\u001b[0m     __headers[\u001b[39m\"\u001b[39m\u001b[39mcontent-type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 3673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperform_request(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   3674\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, __path, params\u001b[39m=\u001b[39;49m__query, headers\u001b[39m=\u001b[39;49m__headers, body\u001b[39m=\u001b[39;49m__body\n\u001b[1;32m   3675\u001b[0m )\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/me/prompt-eng/.venv/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    318\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(meta\u001b[39m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    321\u001b[0m         message\u001b[39m=\u001b[39mmessage, meta\u001b[39m=\u001b[39mmeta, body\u001b[39m=\u001b[39mresp_body\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[39m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    326\u001b[0m     \u001b[39m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: NotFoundError(404, 'resource_not_found_exception', 'Could not find trained model [sentence-transformers__all-distilroberta-v1]')"
     ]
    }
   ],
   "source": [
    "# Initialize Elasticsearch LLM Cache\n",
    "llm_cache = ElasticsearchLLMCache(es)\n",
    "\n",
    "# Query the cache\n",
    "cache_response = llm_cache.query(prompt_text=\"Hello, how can I help?\")\n",
    "\n",
    "# If no cache hit, add new response to cache\n",
    "if not cache_response:\n",
    "    llm_response = \"I'm here to assist you!\"  # Assume this response is fetched from LLM\n",
    "    llm_cache.add(prompt=\"Hello, how can I help?\", response=llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
